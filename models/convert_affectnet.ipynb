{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ed202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55d7a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert done.\n"
     ]
    }
   ],
   "source": [
    "# 0 ~ 7의 label들로 분리\n",
    "\n",
    "df = pd.read_csv('./Dataset/affectnet.csv')\n",
    "\n",
    "for i in range(8):\n",
    "    for j in ['train','val']:\n",
    "        os.makedirs(f'./datasets/AfectNet/{j}/{i}',exist_ok=True)\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    p = row['phase']\n",
    "    l = row['label']\n",
    "    copy(row['img_path'], f'./datasets/AfectNet/{p}/{l}')\n",
    "\n",
    "print('convert done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e997629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def img_crop(file):\n",
    "    img = Image.open(file)\n",
    "    croppedImg = img.crop((72, 0, 360, 288))\n",
    "    croppedImg.save(f'{file[:-4]}_cropped.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3737cdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_pos_LayerCAM.jpg\n",
      "100000_pos_LayerCAM.jpg\n",
      "100001_pos_LayerCAM.jpg\n",
      "100004_pos_LayerCAM.jpg\n",
      "100011_pos_LayerCAM.jpg\n",
      "100015_pos_LayerCAM.jpg\n",
      "100017_pos_LayerCAM.jpg\n",
      "100020_pos_LayerCAM.jpg\n",
      "100022_pos_LayerCAM.jpg\n",
      "100024_pos_LayerCAM.jpg\n",
      "10002_pos_LayerCAM.jpg\n",
      "100033_pos_LayerCAM.jpg\n",
      "100034_pos_LayerCAM.jpg\n",
      "100037_pos_LayerCAM.jpg\n",
      "100038_pos_LayerCAM.jpg\n",
      "10003_pos_LayerCAM.jpg\n",
      "100043_pos_LayerCAM.jpg\n",
      "100046_pos_LayerCAM.jpg\n",
      "100049_pos_LayerCAM.jpg\n",
      "10004_pos_LayerCAM.jpg\n",
      "100051_pos_LayerCAM.jpg\n",
      "100059_pos_LayerCAM.jpg\n",
      "100062_pos_LayerCAM.jpg\n",
      "100065_pos_LayerCAM.jpg\n",
      "100066_pos_LayerCAM.jpg\n",
      "100068_pos_LayerCAM.jpg\n",
      "100069_pos_LayerCAM.jpg\n",
      "100072_pos_LayerCAM.jpg\n",
      "100081_pos_LayerCAM.jpg\n",
      "100082_pos_LayerCAM.jpg\n",
      "100089_pos_LayerCAM.jpg\n",
      "100090_pos_LayerCAM.jpg\n",
      "100095_pos_LayerCAM.jpg\n",
      "100096_pos_LayerCAM.jpg\n",
      "100102_pos_LayerCAM.jpg\n",
      "100104_pos_LayerCAM.jpg\n",
      "100108_pos_LayerCAM.jpg\n",
      "100109_pos_LayerCAM.jpg\n",
      "10010_pos_LayerCAM.jpg\n",
      "100111_pos_LayerCAM.jpg\n",
      "100116_pos_LayerCAM.jpg\n",
      "100118_pos_LayerCAM.jpg\n",
      "100120_pos_LayerCAM.jpg\n",
      "100121_pos_LayerCAM.jpg\n",
      "100122_pos_LayerCAM.jpg\n",
      "100125_pos_LayerCAM.jpg\n",
      "100129_pos_LayerCAM.jpg\n",
      "100131_pos_LayerCAM.jpg\n",
      "100139_pos_LayerCAM.jpg\n",
      "100140_pos_LayerCAM.jpg\n",
      "100144_pos_LayerCAM.jpg\n",
      "100145_pos_LayerCAM.jpg\n",
      "100152_pos_LayerCAM.jpg\n",
      "100159_pos_LayerCAM.jpg\n",
      "100160_pos_LayerCAM.jpg\n",
      "100163_pos_LayerCAM.jpg\n",
      "100165_pos_LayerCAM.jpg\n",
      "100169_pos_LayerCAM.jpg\n",
      "100171_pos_LayerCAM.jpg\n",
      "100173_pos_LayerCAM.jpg\n",
      "100176_pos_LayerCAM.jpg\n",
      "100183_pos_LayerCAM.jpg\n",
      "100187_pos_LayerCAM.jpg\n",
      "100189_pos_LayerCAM.jpg\n",
      "100192_pos_LayerCAM.jpg\n",
      "100193_pos_LayerCAM.jpg\n",
      "1001_pos_LayerCAM.jpg\n",
      "100201_pos_LayerCAM.jpg\n",
      "100204_pos_LayerCAM.jpg\n",
      "100205_pos_LayerCAM.jpg\n",
      "100206_pos_LayerCAM.jpg\n",
      "100207_pos_LayerCAM.jpg\n",
      "100208_pos_LayerCAM.jpg\n",
      "100209_pos_LayerCAM.jpg\n",
      "100211_pos_LayerCAM.jpg\n",
      "100214_pos_LayerCAM.jpg\n",
      "100217_pos_LayerCAM.jpg\n",
      "10021_pos_LayerCAM.jpg\n",
      "100222_pos_LayerCAM.jpg\n",
      "100225_pos_LayerCAM.jpg\n",
      "100226_pos_LayerCAM.jpg\n",
      "100231_pos_LayerCAM.jpg\n",
      "100233_pos_LayerCAM.jpg\n",
      "100237_pos_LayerCAM.jpg\n",
      "100240_pos_LayerCAM.jpg\n",
      "100241_pos_LayerCAM.jpg\n",
      "100242_pos_LayerCAM.jpg\n",
      "100247_pos_LayerCAM.jpg\n",
      "100249_pos_LayerCAM.jpg\n",
      "10024_pos_LayerCAM.jpg\n",
      "100250_pos_LayerCAM.jpg\n",
      "100255_pos_LayerCAM.jpg\n",
      "100261_pos_LayerCAM.jpg\n",
      "100263_pos_LayerCAM.jpg\n",
      "100265_pos_LayerCAM.jpg\n",
      "10026_pos_LayerCAM.jpg\n",
      "100278_pos_LayerCAM.jpg\n",
      "100280_pos_LayerCAM.jpg\n",
      "100281_pos_LayerCAM.jpg\n",
      "100283_pos_LayerCAM.jpg\n",
      "100284_pos_LayerCAM.jpg\n",
      "100286_pos_LayerCAM.jpg\n",
      "100292_pos_LayerCAM.jpg\n",
      "100293_pos_LayerCAM.jpg\n",
      "100298_pos_LayerCAM.jpg\n",
      "1002_pos_LayerCAM.jpg\n",
      "100303_pos_LayerCAM.jpg\n",
      "100306_pos_LayerCAM.jpg\n",
      "100308_pos_LayerCAM.jpg\n",
      "100311_pos_LayerCAM.jpg\n",
      "100312_pos_LayerCAM.jpg\n",
      "100316_pos_LayerCAM.jpg\n",
      "10031_pos_LayerCAM.jpg\n",
      "100322_pos_LayerCAM.jpg\n",
      "100325_pos_LayerCAM.jpg\n",
      "100327_pos_LayerCAM.jpg\n",
      "100331_pos_LayerCAM.jpg\n",
      "100333_pos_LayerCAM.jpg\n",
      "100336_pos_LayerCAM.jpg\n",
      "10033_pos_LayerCAM.jpg\n",
      "100340_pos_LayerCAM.jpg\n",
      "100341_pos_LayerCAM.jpg\n",
      "100343_pos_LayerCAM.jpg\n",
      "100345_pos_LayerCAM.jpg\n",
      "100347_pos_LayerCAM.jpg\n",
      "100350_pos_LayerCAM.jpg\n",
      "100353_pos_LayerCAM.jpg\n",
      "100354_pos_LayerCAM.jpg\n",
      "100356_pos_LayerCAM.jpg\n",
      "100360_pos_LayerCAM.jpg\n",
      "100361_pos_LayerCAM.jpg\n",
      "100362_pos_LayerCAM.jpg\n",
      "100366_pos_LayerCAM.jpg\n",
      "100369_pos_LayerCAM.jpg\n",
      "100370_pos_LayerCAM.jpg\n",
      "100371_pos_LayerCAM.jpg\n",
      "100372_pos_LayerCAM.jpg\n",
      "100373_pos_LayerCAM.jpg\n",
      "100375_pos_LayerCAM.jpg\n",
      "100377_pos_LayerCAM.jpg\n",
      "100378_pos_LayerCAM.jpg\n",
      "100380_pos_LayerCAM.jpg\n",
      "10038_pos_LayerCAM.jpg\n",
      "100390_pos_LayerCAM.jpg\n",
      "100399_pos_LayerCAM.jpg\n",
      "100408_pos_LayerCAM.jpg\n",
      "100410_pos_LayerCAM.jpg\n",
      "100412_pos_LayerCAM.jpg\n",
      "100415_pos_LayerCAM.jpg\n",
      "100416_pos_LayerCAM.jpg\n",
      "100420_pos_LayerCAM.jpg\n",
      "100429_pos_LayerCAM.jpg\n",
      "100431_pos_LayerCAM.jpg\n",
      "100432_pos_LayerCAM.jpg\n",
      "100433_pos_LayerCAM.jpg\n",
      "100435_pos_LayerCAM.jpg\n",
      "100436_pos_LayerCAM.jpg\n",
      "100438_pos_LayerCAM.jpg\n",
      "100446_pos_LayerCAM.jpg\n",
      "100448_pos_LayerCAM.jpg\n",
      "100451_pos_LayerCAM.jpg\n",
      "100454_pos_LayerCAM.jpg\n",
      "100455_pos_LayerCAM.jpg\n",
      "100461_pos_LayerCAM.jpg\n",
      "100463_pos_LayerCAM.jpg\n",
      "100464_pos_LayerCAM.jpg\n",
      "100469_pos_LayerCAM.jpg\n",
      "100470_pos_LayerCAM.jpg\n",
      "100471_pos_LayerCAM.jpg\n",
      "100476_pos_LayerCAM.jpg\n",
      "100477_pos_LayerCAM.jpg\n",
      "100478_pos_LayerCAM.jpg\n",
      "100481_pos_LayerCAM.jpg\n",
      "100483_pos_LayerCAM.jpg\n",
      "100484_pos_LayerCAM.jpg\n",
      "100491_pos_LayerCAM.jpg\n",
      "100494_pos_LayerCAM.jpg\n",
      "100498_pos_LayerCAM.jpg\n",
      "100501_pos_LayerCAM.jpg\n",
      "100503_pos_LayerCAM.jpg\n",
      "100504_pos_LayerCAM.jpg\n",
      "100507_pos_LayerCAM.jpg\n",
      "100509_pos_LayerCAM.jpg\n",
      "100510_pos_LayerCAM.jpg\n",
      "100511_pos_LayerCAM.jpg\n",
      "100513_pos_LayerCAM.jpg\n",
      "10051_pos_LayerCAM.jpg\n",
      "100528_pos_LayerCAM.jpg\n",
      "100529_pos_LayerCAM.jpg\n",
      "100530_pos_LayerCAM.jpg\n",
      "100532_pos_LayerCAM.jpg\n",
      "100535_pos_LayerCAM.jpg\n",
      "100536_pos_LayerCAM.jpg\n",
      "100549_pos_LayerCAM.jpg\n",
      "10054_pos_LayerCAM.jpg\n",
      "100551_pos_LayerCAM.jpg\n",
      "100553_pos_LayerCAM.jpg\n",
      "100558_pos_LayerCAM.jpg\n",
      "100559_pos_LayerCAM.jpg\n",
      "10055_pos_LayerCAM.jpg\n",
      "100560_pos_LayerCAM.jpg\n",
      "100561_pos_LayerCAM.jpg\n",
      "100562_pos_LayerCAM.jpg\n",
      "100568_pos_LayerCAM.jpg\n",
      "100569_pos_LayerCAM.jpg\n",
      "100574_pos_LayerCAM.jpg\n",
      "100575_pos_LayerCAM.jpg\n",
      "100576_pos_LayerCAM.jpg\n",
      "100578_pos_LayerCAM.jpg\n",
      "100582_pos_LayerCAM.jpg\n",
      "100586_pos_LayerCAM.jpg\n",
      "100587_pos_LayerCAM.jpg\n",
      "100588_pos_LayerCAM.jpg\n",
      "100589_pos_LayerCAM.jpg\n",
      "10058_pos_LayerCAM.jpg\n",
      "100593_pos_LayerCAM.jpg\n",
      "100598_pos_LayerCAM.jpg\n",
      "100599_pos_LayerCAM.jpg\n",
      "100605_pos_LayerCAM.jpg\n",
      "10060_pos_LayerCAM.jpg\n",
      "100613_pos_LayerCAM.jpg\n",
      "100614_pos_LayerCAM.jpg\n",
      "100616_pos_LayerCAM.jpg\n",
      "100619_pos_LayerCAM.jpg\n",
      "100620_pos_LayerCAM.jpg\n",
      "100623_pos_LayerCAM.jpg\n",
      "100624_pos_LayerCAM.jpg\n",
      "100629_pos_LayerCAM.jpg\n",
      "10062_pos_LayerCAM.jpg\n",
      "100630_pos_LayerCAM.jpg\n",
      "100632_pos_LayerCAM.jpg\n",
      "100638_pos_LayerCAM.jpg\n",
      "10_pos_LayerCAM.jpg\n"
     ]
    }
   ],
   "source": [
    "file_dir = './result/posmodel_pos_img/'\n",
    "file_names = os.listdir(file_dir)\n",
    "for file in file_names:\n",
    "    print(file)\n",
    "    img_crop(f'./result/posmodel_pos_img/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d95eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory의 데이터 개수 확인\n",
    "def file_size(directory):\n",
    "    print(len(os.listdir(file_dir + directory)))\n",
    "\n",
    "# dif_from 의 데이터를 dir_to 로 n_move개 만큼 이동\n",
    "def file_move(dir_from, dir_to, n_move):\n",
    "    file_dir = './datasets/AfectNet/'\n",
    "    file_dest = './datasets/AfectNet/train'\n",
    "    \n",
    "    list_x = os.listdir(file_dir + dir_from)\n",
    "    df_x = pd.DataFrame(list_x).sample(n = n_move, random_state = 2022)\n",
    "    sample_x = list(df_x.loc[:, 0])\n",
    "    \n",
    "    for i in os.listdir(sample_x):\n",
    "        shutil.move(file_dir + dir_from + '/' + i, dir_to)\n",
    "        \n",
    "def file_move_pos(folder, n_move):\n",
    "    list1 = []\n",
    "    list1 = os.listdir(file_dir + folder)\n",
    "    \n",
    "    df1 = pd.DataFrame(list1).sample(n = n_move, random_state = 2022)\n",
    "    \n",
    "    sample1 = list(df1.loc[:, 0])\n",
    "    \n",
    "    for i in sample1:\n",
    "        shutil.move(file_dir + folder + i, file_dest + '/pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb89a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0:\n",
      "74873\n",
      "None\n",
      "Index 1:\n",
      "134415\n",
      "None\n",
      "Index 2:\n",
      "25459\n",
      "None\n",
      "Index 3:\n",
      "14090\n",
      "None\n",
      "Index 4:\n",
      "6378\n",
      "None\n",
      "Index 5:\n",
      "3803\n",
      "None\n",
      "Index 6:\n",
      "24882\n",
      "None\n",
      "Index 7:\n",
      "3750\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# train data 개수\n",
    "file_dir = './datasets/AfectNet'\n",
    "for i in range(8):\n",
    "    print(f'Index {i}:')\n",
    "    print(file_size('/train_og/' + str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33329de0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0:\n",
      "500\n",
      "None\n",
      "Index 1:\n",
      "500\n",
      "None\n",
      "Index 2:\n",
      "500\n",
      "None\n",
      "Index 3:\n",
      "500\n",
      "None\n",
      "Index 4:\n",
      "500\n",
      "None\n",
      "Index 5:\n",
      "500\n",
      "None\n",
      "Index 6:\n",
      "500\n",
      "None\n",
      "Index 7:\n",
      "499\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# validation data 개수\n",
    "for i in range(8):\n",
    "    print(f'Index {i}:')\n",
    "    print(file_size('/val_og/' + str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5539cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "file_path = './datasets/AfectNet/val_og/0'\n",
    "file_names = os.listdir(file_path)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for file in file_names:\n",
    "    src = os.path.join(file_path, file)\n",
    "    dst = '0_' + str(i) + '.jpg'\n",
    "    dst = os.path.join('./datasets/AfectNet/val_og/0', dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "397b1bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike or None, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# (pos, neu), (neg, neu) binary classification 분리\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# pos: 1, 3 --- 30000개(각각 15000개씩)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# neg: 2, 4, 5, 6, 7 --- 30000개(각각 6000개씩)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# neu: 0 --- 30000개\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# neu 이동\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mfile_move\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/train_og/0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./datasets/AfectNet/train/pos/neu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m file_move(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train_og/0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/AfectNet/train/neg/neu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30000\u001b[39m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mfile_move\u001b[1;34m(dir_from, dir_to, n_move)\u001b[0m\n\u001b[0;32m     10\u001b[0m df_x \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(list_x)\u001b[38;5;241m.\u001b[39msample(n \u001b[38;5;241m=\u001b[39m n_move, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2022\u001b[39m)\n\u001b[0;32m     11\u001b[0m sample_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df_x\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_x\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mmove(file_dir \u001b[38;5;241m+\u001b[39m dir_from \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m i, dir_to)\n",
      "\u001b[1;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike or None, not list"
     ]
    }
   ],
   "source": [
    "# (pos, neu), (neg, neu) binary classification 분리\n",
    "# pos: 1, 3 --- 30000개(각각 15000개씩)\n",
    "# neg: 2, 4, 5, 6, 7 --- 30000개(각각 6000개씩)\n",
    "# neu: 0 --- 30000개\n",
    "\n",
    "file_dir = './datasets/AfectNet/train'\n",
    "file_dest = './datasets/AfectNet/'\n",
    "# neu 이동\n",
    "file_move_pos('/1', 30000)\n",
    "file_move1('/train_og/0', './datasets/AfectNet/train/neg/neu', 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos 이동\n",
    "file_move('/train_og/1', './datasets/AfectNet/train/pos/pos', 15000)\n",
    "file_move('/train_og/3', './datasets/AfectNet/train/pos/pos', 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b799cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# (pos, neu), (neg, neu) binary classification 분리\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# pos: 1, 3 --- 30000개(각각 15000개씩)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# neg: 2, 4, 5, 6, 7 --- 30000개(각각 6000개씩)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# neu: 0 --- 30000개\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# neu 이동\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mfile_move\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/train_og/0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./datasets/AfectNet/train/pos/neu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m file_move(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train_og/0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/AfectNet/train/neg/neu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30000\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# pos 이동\u001b[39;00m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mfile_move\u001b[1;34m(dir_from, dir_to, n_move)\u001b[0m\n\u001b[0;32m      7\u001b[0m file_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/AfectNet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m list_x \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(file_dir \u001b[38;5;241m+\u001b[39m dir_from)\n\u001b[1;32m---> 10\u001b[0m df_x \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_x\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_move\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m sample_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df_x\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(sample_x):\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\generic.py:5446\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m-> 5446\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5447\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   5449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\sample.py:150\u001b[0m, in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[0;32m    151\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    152\u001b[0m )\n",
      "File \u001b[1;32mmtrand.pyx:909\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# neg 이동\n",
    "file_move('/train_og/2', './datasets/AfectNet/train/neg/neg', 6000)\n",
    "file_move('/train_og/4', './datasets/AfectNet/train/neg/neg', 6000)\n",
    "file_move('/train_og/5', './datasets/AfectNet/train/neg/neg', 6000)\n",
    "file_move('/train_og/6', './datasets/AfectNet/train/neg/neg', 6000)\n",
    "file_move('/train_og/7', './datasets/AfectNet/train/neg/neg', 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a94491f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './datasets/AfectNet/train'\n",
    "\n",
    "list_1 = []\n",
    "list_1 = os.listdir(file_dir + '/neg_all')\n",
    "\n",
    "df1 = pd.DataFrame(list_1).sample(n = 30000, random_state = 2022)\n",
    "\n",
    "sample1 = list(df1.loc[:, 0])\n",
    "\n",
    "file_dest = './datasets/AfectNet/train'\n",
    "for i in sample1:\n",
    "    shutil.move(file_dir + '/neg_all/' + i, file_dest + '/neg/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aac602be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './datasets/AfectNet/train_og'\n",
    "\n",
    "list_1 = []\n",
    "list_1 = os.listdir(file_dir + '/7')\n",
    "\n",
    "df1 = pd.DataFrame(list_1)\n",
    "\n",
    "sample1 = list(df1.loc[:, 0])\n",
    "\n",
    "file_dest = './datasets/AfectNet/train'\n",
    "for i in sample1:\n",
    "    shutil.move(file_dir + '/7/' + i, file_dest + '/neg_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a781b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './datasets/AfectNet/val'\n",
    "\n",
    "list_1 = []\n",
    "list_1 = os.listdir(file_dir + '/neg/neg')\n",
    "\n",
    "df1 = pd.DataFrame(list_1).sample(n = 1000, random_state = 2022)\n",
    "\n",
    "sample1 = list(df1.loc[:, 0])\n",
    "\n",
    "file_dest = './datasets/AfectNet/val'\n",
    "for i in sample1:\n",
    "    shutil.move(file_dir + '/neg/neg/' + i, file_dest + '/neg/neg1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b1694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
